{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,string\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\sahil computer\\\\Desktop\\\\20_newsgroups')\n",
    "#for getting each folder name\n",
    "folders=os.listdir()\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'49960'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:/Users/sahil computer/Desktop/20_newsgroups/alt.atheism')\n",
    "#for accessing each file in a folder\n",
    "b=os.listdir()\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing available data\n",
    "data=[]\n",
    "for i in folders:\n",
    "    os.chdir('C:/Users/sahil computer/Desktop/20_newsgroups/'+i)\n",
    "    b=os.listdir()\n",
    "    for j in b:\n",
    "        data.append((os.getcwd()+'/'+j,i))\n",
    "        \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list into required dataframe to split into train and test\n",
    "df_total_data=pd.DataFrame((data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14997, 2), (5000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df_total_data)\n",
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=np.array(df_train.iloc[:,0])\n",
    "y_train=np.array(df_train.iloc[:,1])\n",
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=np.array(df_test.iloc[:,0])\n",
    "y_test=np.array(df_test.iloc[:,1])\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open('C:/Users/sahil computer/Downloads/stopwords_en.txt')\n",
    "stop_word_list=f1.read().split()\n",
    "#stop word list\n",
    "#f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing all punctuation marks \n",
    "p_marks=set(string.punctuation)\n",
    "#p_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={}\n",
    "for i in range(x_train.shape[0]):\n",
    "        list1=0\n",
    "        list2=0\n",
    "        list3=0\n",
    "        list=0\n",
    "        list4=0\n",
    "        obj=open(x_train[i],errors=\"ignore\")\n",
    "        #print(c)\n",
    "        c=obj.readlines()\n",
    "        list=(\" \".join(c[7:])).lower().split()\n",
    "        \n",
    "        #removing stop words\n",
    "        list1=' '.join(i for i in list if i.lower() not in (x.lower() for x in stop_word_list))\n",
    "        \n",
    "        #removing punctuation_marks\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        list2=''.join(ch for ch in list1 if ch not in p_marks)\n",
    "        \n",
    "        #removing digits\n",
    "        list3=\"\".join([c for c in list2 if not c.isdigit()])\n",
    "        \n",
    "        #creating dictionary\n",
    "        list4=list3.split()\n",
    "        for i in list4:\n",
    "            if i in dict:\n",
    "                dict[i]+=1\n",
    "            else:\n",
    "                dict[i]=1\n",
    "                \n",
    "len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132021"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to sort dictionary according to frequency values\n",
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "final_words=sorted_dict[:4000]\n",
    "len(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing values of all words with high frequency\n",
    "values=[]\n",
    "for i in range(len(final_words)):\n",
    "    values.append(final_words[i][0])\n",
    "    \n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating basic structure of dataframe\n",
    "x=np.zeros((14997,4000))\n",
    "\n",
    "final_df=pd.DataFrame(x,columns=values)\n",
    "#final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'writes'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for storing names of features\n",
    "col_val=final_df.columns\n",
    "col_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing frequency in whole dataframe \n",
    "index=0\n",
    "for i in range(x_train.shape[0]):\n",
    "        list1=[]\n",
    "        list2=[]\n",
    "        list3=[]\n",
    "        list=[]\n",
    "        list4=[]\n",
    "        obj=open(x_train[i],errors=\"ignore\")\n",
    "        #print(c)\n",
    "        c=obj.readlines()\n",
    "        list=(\" \".join(c[7:])).lower().split()\n",
    "        \n",
    "        list1=' '.join(i for i in list if i.lower() not in (x.lower() for x in stop_word_list))\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        list2=''.join(ch for ch in list1 if ch not in p_marks)\n",
    "        list3=\"\".join([c for c in list2 if not c.isdigit()])\n",
    "        list4=list3.split()\n",
    "\n",
    "        for k in list4:\n",
    "            if k in col_val:\n",
    "                final_df[k][index]+=1\n",
    "                \n",
    "        index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x,y):\n",
    "    counts={}\n",
    "    class_values=set(y)\n",
    "    for current_class in class_values:\n",
    "        total=0\n",
    "        counts[current_class]={}\n",
    "        rows_with_current_class=(y==current_class)\n",
    "        x_current_class=x[rows_with_current_class]\n",
    "        y_current_class=y[rows_with_current_class]\n",
    "        for p in range(x_current_class.shape[0]):\n",
    "            for z in range(x_current_class.shape[1]):\n",
    "                total+=x_current_class[p][z]\n",
    "        counts[current_class][\"total_count\"]=total\n",
    "        \n",
    "        for i in range(x_current_class.shape[1]):\n",
    "            q=0\n",
    "            for j in range(x_current_class.shape[0]):\n",
    "                q+=x_current_class[j][i]\n",
    "            counts[current_class][i]=q\n",
    "\n",
    "    return counts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=fit(final_df.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,counts):\n",
    "    output=[]\n",
    "    for x in x_test:\n",
    "        output.append(predictSingle(x,counts))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSingle(x,counts):\n",
    "    max_pr=float(\"-inf\")\n",
    "    classes=counts.keys()\n",
    "    for c in classes:\n",
    "        p=findSingleClassProb(x,counts,c)\n",
    "        if p>max_pr:\n",
    "            max_pr=p\n",
    "            max_class=c\n",
    "    return max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSingleClassProb(x,counts,c):\n",
    "    ans=0\n",
    "    for i in range(len(x)):\n",
    "        pr_feat=math.log((counts[c][i]+1))-math.log((counts[c][\"total_count\"]+4000))\n",
    "        log_prob=pr_feat*x[i]\n",
    "        ans+=log_prob\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df=np.zeros((5000,4000))\n",
    "x_df=pd.DataFrame(x_df,columns=values)\n",
    "x_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "for i in range(x_test.shape[0]):\n",
    "        list1=0\n",
    "        list2=0\n",
    "        list3=0\n",
    "        list=0\n",
    "        list4=0\n",
    "        obj=open(x_test[i],errors=\"ignore\")\n",
    "        #print(c)\n",
    "        c=obj.readlines()\n",
    "        list=(\" \".join(c[7:])).lower().split()\n",
    "        \n",
    "        list1=' '.join(i for i in list if i.lower() not in (x.lower() for x in stop_word_list))\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        list2=''.join(ch for ch in list1 if ch not in p_marks)\n",
    "        list3=\"\".join([c for c in list2 if not c.isdigit()])\n",
    "        list4=list3.split()\n",
    "\n",
    "        for k in list4:\n",
    "            if k in col_val:\n",
    "                x_df[k][index]+=1\n",
    "                #for j in range(len(col_val)):\n",
    "                   # if k==col_val[j]:\n",
    "                    #    x.iloc[i,j]+=1\n",
    "        index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=predict(x_df.values,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_pred=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.78      0.72       244\n",
      "           comp.graphics       0.68      0.67      0.67       240\n",
      " comp.os.ms-windows.misc       0.75      0.61      0.67       257\n",
      "comp.sys.ibm.pc.hardware       0.68      0.69      0.69       265\n",
      "   comp.sys.mac.hardware       0.72      0.81      0.76       254\n",
      "          comp.windows.x       0.79      0.78      0.79       250\n",
      "            misc.forsale       0.74      0.83      0.78       270\n",
      "               rec.autos       0.82      0.86      0.84       270\n",
      "         rec.motorcycles       0.72      0.91      0.81       235\n",
      "      rec.sport.baseball       0.89      0.91      0.90       238\n",
      "        rec.sport.hockey       0.95      0.90      0.93       257\n",
      "               sci.crypt       0.91      0.87      0.89       242\n",
      "         sci.electronics       0.72      0.72      0.72       253\n",
      "                 sci.med       0.89      0.82      0.85       276\n",
      "               sci.space       0.91      0.86      0.88       234\n",
      "  soc.religion.christian       0.87      0.96      0.92       225\n",
      "      talk.politics.guns       0.67      0.86      0.76       237\n",
      "   talk.politics.mideast       0.95      0.84      0.89       257\n",
      "      talk.politics.misc       0.70      0.52      0.60       262\n",
      "      talk.religion.misc       0.56      0.41      0.48       234\n",
      "\n",
      "               micro avg       0.78      0.78      0.78      5000\n",
      "               macro avg       0.78      0.78      0.78      5000\n",
      "            weighted avg       0.78      0.78      0.78      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
